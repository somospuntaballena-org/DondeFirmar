name: Scheduled KML Extraction

on:
  schedule:
    # Runs at the start of every hour
    #- cron: '0 * * * *'
    # Runs every 10 minutes
    - cron: '*/10 * * * *'

jobs:
  run_script_and_commit:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
      with:
        fetch-depth: 0  # Ensures history is fully fetched

    - name: Install Pandoc
      run: |
        sudo apt-get update
        sudo apt-get install -y pandoc
        sudo apt-get install -y texlive-xetex

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Run script
      run: |
        python extract_kml_info.py

    - name: Check if CSV changed
      run: |
        cd output
        CSV_FILES=($(ls -Art firmas_*.csv)) # Create an array of CSV files sorted by modification time
        NUM_CSV_FILES=${#CSV_FILES[@]} # Get the number of CSV files

        if [ "$NUM_CSV_FILES" -eq 1 ]; then
          echo "Only one CSV file found. Assuming changes."
          echo "changed=true" >> $GITHUB_ENV
        else
          LATEST_CSV=${CSV_FILES[-1]} # Get the latest CSV file
          SECOND_LATEST_CSV=${CSV_FILES[-2]} # Get the second latest CSV file
          
          # Use 'cmp' for binary comparison, it's faster and sufficient for checking if files are identical
          if cmp -s "$LATEST_CSV" "$SECOND_LATEST_CSV"; then
            echo "No changes in the CSV files."
            echo "changed=false" >> $GITHUB_ENV
          else
            echo "CSV files have changed."
            echo "changed=true" >> $GITHUB_ENV
          fi
        fi

    - name: Commit and force push if changed
      if: env.changed == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Navigate to the output directory
        cd output
        
        # FIXME Assuming new files have already been generated by the script in the output directory:
        # First, remove any tracked files in the repository within the output directory
        # git rm -rf --cached ./*

        # Copy the generated HTML file into a text file.
        LATEST_HTML=$(ls -Art firmas_*.html | tail -n 1)
        TXT_FILENAME="latest.txt"
        cp "${LATEST_HTML}" "${TXT_FILENAME}"

        # Copy the generated PDF file into a new file.
        LATEST_PDF=$(ls -Art firmas_*.pdf | tail -n 1)
        PDF_FILENAME="latest.pdf"
        cp "${LATEST_PDF}" "${PDF_FILENAME}"
        
        # Add the newly generated files to staging
        git add .
        
        # Commit the changes. This commit will include the removal of old files and addition of new ones
        git commit -m "Update output files with latest run"
        
        # Navigate back to the root of the repository
        cd ..
        
        # Force push to overwrite history on the current branch
        git push origin HEAD:main --force
